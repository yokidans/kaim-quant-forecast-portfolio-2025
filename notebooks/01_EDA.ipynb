{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # Task 01 — Exploratory Data Analysis (EDA)\n",
    "#\n",
    "# **Project:** KAIM Quant Forecast & Portfolio Optimization 2025  \n",
    "# **Notebook:** 01_EDA.ipynb  \n",
    "# **Purpose:** Load processed TSLA, BND, SPY daily data (2015-07-01 → 2025-07-31), perform statistical & visual EDA as per brief.  \n",
    "# **Author:** [Your Name]\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ## Objectives (from project brief)\n",
    "# - Check data quality (types, missing values, date alignment)\n",
    "# - Compute descriptive stats (mean, volatility, skew, kurtosis)\n",
    "# - Plot time series for adjusted close, returns, rolling volatility\n",
    "# - Detect & quantify outliers in returns\n",
    "# - Run Augmented Dickey-Fuller tests for stationarity\n",
    "# - Compute risk metrics: historical VaR, Sharpe ratio\n",
    "# - Document insights for each plot/test (investment-relevant interpretation)\n",
    "#\n",
    "# ## Why this matters:\n",
    "# EDA is **decision insurance** — before modeling, we need to be sure our data is valid, aligned, and that we understand statistical properties that will affect forecasts and portfolio construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "PROC_DIR = Path(\"../data/processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Load processed data\n",
    "# Data comes from `src/data/preprocess.py` — aligned on business days, with `*_adj` and `*_ret` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df = pd.read_csv(PROC_DIR / \"combined_adj_and_returns.csv\", index_col=0, parse_dates=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Insight:**  \n",
    "# - Columns: `TSLA_adj`, `TSLA_ret`, `BND_adj`, `BND_ret`, `SPY_adj`, `SPY_ret`  \n",
    "# - Frequency: business days.  \n",
    "# - Return columns are simple daily returns.  \n",
    "# - Price columns will be used for plotting long-term trends; return columns for volatility & risk metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "missing_counts = df.isna().sum()\n",
    "dtypes = df.dtypes\n",
    "date_min, date_max = df.index.min(), df.index.max()\n",
    "\n",
    "print(\"Missing values:\\n\", missing_counts)\n",
    "print(\"\\nData types:\\n\", dtypes)\n",
    "print(f\"\\nDate range: {date_min} → {date_max}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - Any persistent NaNs in returns after preprocessing suggest corporate actions or missing market data — would require forward/backward fill decisions.  \n",
    "# - Date alignment ensures covariance matrix in portfolio step is valid.  \n",
    "# - Non-float types in price/returns columns would break model fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "desc_stats = {}\n",
    "for ticker in [\"TSLA\", \"BND\", \"SPY\"]:\n",
    "    ret = df[f\"{ticker}_ret\"].dropna()\n",
    "    desc_stats[ticker] = {\n",
    "        \"mean_daily\": ret.mean(),\n",
    "        \"ann_mean\": ret.mean()*252,\n",
    "        \"std_daily\": ret.std(),\n",
    "        \"ann_vol\": ret.std()*np.sqrt(252),\n",
    "        \"skew\": skew(ret),\n",
    "        \"kurtosis\": kurtosis(ret, fisher=True)\n",
    "    }\n",
    "\n",
    "pd.DataFrame(desc_stats).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - TSLA expected to have higher annualized volatility (>50%) vs BND (<10%).  \n",
    "# - Skew/kurtosis tell us about fat tails & asymmetry — TSLA typically shows positive skew but heavy tails (kurtosis >> 3).  \n",
    "# - BND’s low vol and near-normal distribution is bond-typical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Price series plots\n",
    "# Visual inspection of price trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "fig, ax = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "for i, ticker in enumerate([\"TSLA\", \"BND\", \"SPY\"]):\n",
    "    ax[i].plot(df.index, df[f\"{ticker}_adj\"], label=f\"{ticker} Adj Close\")\n",
    "    ax[i].set_title(f\"{ticker} Adjusted Close Price\")\n",
    "    ax[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - TSLA shows explosive growth periods & sharp drawdowns — relevant for model non-stationarity.  \n",
    "# - BND stable, mean-reverting range; SPY upward trend with crises visible (e.g., COVID, 2022 rate hikes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Returns distribution\n",
    "# Histograms + KDE for each asset’s daily returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Rolling volatility (30-day annualized)\n",
    "# Helps identify regime changes in risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "window = 30\n",
    "fig, ax = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "for i, ticker in enumerate([\"TSLA\", \"BND\", \"SPY\"]):\n",
    "    vol = df[f\"{ticker}_ret\"].rolling(window).std()*np.sqrt(252)\n",
    "    ax[i].plot(vol, label=f\"{ticker} 30-day Annualized Vol\")\n",
    "    ax[i].set_title(f\"{ticker} Rolling Volatility ({window} days)\")\n",
    "    ax[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - Volatility clusters — high vol persists; models may benefit from GARCH-like terms.  \n",
    "# - TSLA volatility spikes align with market stress and company events (e.g., earnings).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Outlier detection\n",
    "# Identify top 5 absolute daily returns for each asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "outliers = {}\n",
    "for ticker in [\"TSLA\", \"BND\", \"SPY\"]:\n",
    "    abs_ret = df[f\"{ticker}_ret\"].abs()\n",
    "    top5 = abs_ret.sort_values(ascending=False).head(5)\n",
    "    outliers[ticker] = df.loc[top5.index, [f\"{ticker}_ret\"]]\n",
    "\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# Outliers are often linked to macro events (Fed announcements, pandemics) or idiosyncratic shocks (TSLA earnings).  \n",
    "# They influence VaR & model training; consider robust estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Augmented Dickey-Fuller (ADF) tests\n",
    "# Test for stationarity in prices and returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def adf_test(series):\n",
    "    res = adfuller(series.dropna(), autolag='AIC')\n",
    "    return {\"ADF Stat\": res[0], \"p-value\": res[1], \"# Lags\": res[2], \"# Observations\": res[3]}\n",
    "\n",
    "adf_results = {}\n",
    "for ticker in [\"TSLA\", \"BND\", \"SPY\"]:\n",
    "    adf_results[f\"{ticker}_price\"] = adf_test(df[f\"{ticker}_adj\"])\n",
    "    adf_results[f\"{ticker}_return\"] = adf_test(df[f\"{ticker}_ret\"])\n",
    "\n",
    "pd.DataFrame(adf_results).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - Price series p-values > 0.05 → fail to reject unit root → non-stationary (expected).  \n",
    "# - Return series p-values < 0.05 → reject unit root → stationary (required for ARIMA without extra differencing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 10. Risk metrics — VaR & Sharpe\n",
    "# Value at Risk (5%) and annualized Sharpe ratio for each asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def var_historic(returns, level=0.05):\n",
    "    return np.percentile(returns.dropna(), 100*level)\n",
    "\n",
    "def sharpe_ratio(returns, risk_free=0.0):\n",
    "    ann_ret = returns.mean()*252\n",
    "    ann_vol = returns.std()*np.sqrt(252)\n",
    "    return (ann_ret - risk_free) / ann_vol\n",
    "\n",
    "risk_metrics = {}\n",
    "for ticker in [\"TSLA\", \"BND\", \"SPY\"]:\n",
    "    ret = df[f\"{ticker}_ret\"]\n",
    "    risk_metrics[ticker] = {\n",
    "        \"VaR_5%\": var_historic(ret, 0.05),\n",
    "        \"Sharpe\": sharpe_ratio(ret)\n",
    "    }\n",
    "\n",
    "pd.DataFrame(risk_metrics).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - TSLA’s VaR (5%) may be several times larger than BND’s — risk budgeting must account for position sizing.  \n",
    "# - Sharpe >1 for SPY historically — robust core holding; TSLA’s Sharpe depends heavily on time period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 11. Summary Table for Memo\n",
    "# Consolidate key metrics into one table for the Investment Memo appendix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "summary_df = pd.concat([\n",
    "    pd.DataFrame(desc_stats).T[[\"ann_mean\", \"ann_vol\"]],\n",
    "    pd.DataFrame(risk_metrics).T\n",
    "], axis=1)\n",
    "summary_df.to_csv(\"../reports/EDA_summary_metrics.csv\")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# **Elite insight:**  \n",
    "# - This table can be inserted directly into the Investment Memo appendix.  \n",
    "# - For portfolio optimization, `ann_mean` and `ann_vol` provide intuition, but expected returns for TSLA will come from forecast model (Task 4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 12. Next steps (from EDA to modeling)\n",
    "# - Confirm returns stationarity for ARIMA.  \n",
    "# - Consider volatility modeling (GARCH) if volatility clustering is strong.  \n",
    "# - Remove/flag outliers if they unduly influence model fit.  \n",
    "# - Proceed to Task 2 modeling with cleaned returns & prices.\n",
    "#\n",
    "# **EDA complete.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
